---
layout: page
title:  "skip list"
date:   2018-04-22 00:00:00
category: algorithm
tags: skip-list
---

1,000,000개의 linked list가 있다. 이를 999,999번째 node를 빠르게 찾아가려면 어떻게 해야할까? 

<!-- more -->

---

### skip list

언제나 그랬듯. 속도를 취하려면 메모리를 희생해야한다. linked list 중간에 접근할 수 있어야 search 속도가 빨라질 것이다. linked list를 확장시켜보자. 

기존 linked list를 level 0이라고 하자. level 0을 기준으로, 이 linked list의 중간에 접근할 수 있도록 index역할을 할 linked list를 새로 만들어 주고 이 linked list를 level 1이라고 하자. 이런식으로 list를 만들다보면 다음과 같은 구조가 나온다.

![skip0]({{site.url}}/assets/algorithm/skip0.png){:height="250px" .center-image}

다음 구조는 1~16으로 주어진 데이터에 대하여 level $$i+1$$일때, $$2^{i+1} \times n$$번째에서 level $$i$$로의 pointer를 가지는 구조이다.


말로 하니 표현이 잘 안되는데, 어떤식으로 탐색을 하고 삽입을 하는지는 아래 짤을 보면 쉽게 이해가능하다.
![skip2]({{site.url}}/assets/algorithm/skip2.gif){:height="250px" .center-image}

---

이쯤되면 의문이 생긴다. 처음 데이터에 대해 적당한 구조를 만들어봐야 삽입을 계속하다보면 구조가 다 흐트러지는 것 아닌가?  

그래서, skip list에서는 어떤 level의 linked-list에서 어떤 node가 상위 level과 이어질 것일지를 확률을 통해 얻는다. 확률적인 방법을 통해 dynamic하게 상위 level의 linked list를 만들 수 있다. 일반적으로 p = 1/2 혹은 1/4이 사용된다.

---

각 node에서 몇 개의 포인터가 사용되는지를 구해보면 다음과 같다.
$$\sum_{n=1}^{\infty}nP(X=n) = \sum_{n=1}^{\infty}np^{n-1}(1-p) = \frac{1}{1-p}$$

이는 p를 줄이면 메모리 사용량을 줄일 수 있다는 말이다. 물론 시간은 조금 더 걸릴 것이다. p에 따라 메모리와 시간의 tradeoff가 발생함에도 여전히 $$O(\log{n})$$에 search를 끝낼 수 있다.

---

skip list는 다음과 같이 생기게 된다.
![skip1]({{site.url}}/assets/algorithm/skip1.png){:height="200px" .center-image}


---

참고)  
https://www.slideshare.net/jongwookkim/skip-list  
https://en.wikipedia.org/wiki/Skip_list
